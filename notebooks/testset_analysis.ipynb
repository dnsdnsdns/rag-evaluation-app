{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6b2cc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3894c2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datei laden\n",
    "with open(\"../data/validationset.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f70da1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "singleturn/specific: 92 samples\n",
      "singleturn/seminar-search: 55 samples\n",
      "singleturn/handoff: 57 samples\n",
      "singleturn/out-of-scope: 30 samples\n",
      "singleturn/bad-intentions: 45 samples\n",
      "singleturn/abstract: 30 samples\n",
      "multiturn/specific: 51 samples\n",
      "multiturn/seminar-search: 33 samples\n",
      "multiturn/handoff: 30 samples\n",
      "multiturn/out-of-scope: 24 samples\n",
      "multiturn/bad-intentions: 11 samples\n",
      "multiturn/abstract: 10 samples\n"
     ]
    }
   ],
   "source": [
    "# Anzahl Samples je Kategorie\n",
    "for turn_type in [\"singleturn\", \"multiturn\"]:\n",
    "    for category, sample_list in data[turn_type].items():\n",
    "        num_samples = len(sample_list)\n",
    "        print(f\"{turn_type}/{category}: {num_samples} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "833e7198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1581,\n",
       " {'singleturn/specific': 460,\n",
       "  'singleturn/seminar-search': 220,\n",
       "  'singleturn/handoff': 114,\n",
       "  'singleturn/out-of-scope': 60,\n",
       "  'singleturn/bad-intentions': 90,\n",
       "  'singleturn/abstract': 90,\n",
       "  'multiturn/specific': 255,\n",
       "  'multiturn/seminar-search': 132,\n",
       "  'multiturn/handoff': 60,\n",
       "  'multiturn/out-of-scope': 48,\n",
       "  'multiturn/bad-intentions': 22,\n",
       "  'multiturn/abstract': 30})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluierungskriterien\n",
    "criteria = data[\"evaluation_criteria\"]\n",
    "\n",
    "# Sample-Sets\n",
    "samples = {\n",
    "    \"singleturn\": data[\"singleturn\"],\n",
    "    \"multiturn\": data[\"multiturn\"]\n",
    "}\n",
    "\n",
    "# Berechnung der Gesamtanzahl an Beurteilungen\n",
    "total_evaluations = 0\n",
    "evaluations_by_category = defaultdict(int)\n",
    "\n",
    "# FÃ¼r jede Dialogart (singleturn, multiturn)\n",
    "for turn_type in [\"singleturn\", \"multiturn\"]:\n",
    "    for category, sample_list in samples[turn_type].items():\n",
    "        num_samples = len(sample_list)\n",
    "        num_criteria = len(criteria[turn_type][category])\n",
    "        evaluations = num_samples * num_criteria\n",
    "        total_evaluations += evaluations\n",
    "        evaluations_by_category[f\"{turn_type}/{category}\"] = evaluations\n",
    "\n",
    "total_evaluations, dict(evaluations_by_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "174a976a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = Path(\"../data/validationset.json\")\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Approximate token count (using space-separated word count * 1.3 to simulate tokenization)\n",
    "def count_tokens(text):\n",
    "    if not text:\n",
    "        return 0\n",
    "    return int(len(text.split()) * 1.3)\n",
    "\n",
    "evaluation_criteria = data[\"evaluation_criteria\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ce0f5f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "mode",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "category",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "metric",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "token_count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "83aa6c92-c1e7-4f6b-ac26-8f50a7360253",
       "rows": [
        [
         "0",
         "0001",
         "singleturn",
         "specific",
         "faithfulness",
         "910"
        ],
        [
         "1",
         "0001",
         "singleturn",
         "specific",
         "answer_relevance",
         "80"
        ],
        [
         "2",
         "0001",
         "singleturn",
         "specific",
         "answer_correctness",
         "112"
        ],
        [
         "3",
         "0001",
         "singleturn",
         "specific",
         "context_relevance",
         "848"
        ],
        [
         "4",
         "0001",
         "singleturn",
         "specific",
         "quality_pairwise",
         "151"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>mode</th>\n",
       "      <th>category</th>\n",
       "      <th>metric</th>\n",
       "      <th>token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001</td>\n",
       "      <td>singleturn</td>\n",
       "      <td>specific</td>\n",
       "      <td>faithfulness</td>\n",
       "      <td>910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001</td>\n",
       "      <td>singleturn</td>\n",
       "      <td>specific</td>\n",
       "      <td>answer_relevance</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0001</td>\n",
       "      <td>singleturn</td>\n",
       "      <td>specific</td>\n",
       "      <td>answer_correctness</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001</td>\n",
       "      <td>singleturn</td>\n",
       "      <td>specific</td>\n",
       "      <td>context_relevance</td>\n",
       "      <td>848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001</td>\n",
       "      <td>singleturn</td>\n",
       "      <td>specific</td>\n",
       "      <td>quality_pairwise</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id        mode  category              metric  token_count\n",
       "0  0001  singleturn  specific        faithfulness          910\n",
       "1  0001  singleturn  specific    answer_relevance           80\n",
       "2  0001  singleturn  specific  answer_correctness          112\n",
       "3  0001  singleturn  specific   context_relevance          848\n",
       "4  0001  singleturn  specific    quality_pairwise          151"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count tokens for validationset\n",
    "\n",
    "results = []\n",
    "\n",
    "for mode in [\"singleturn\", \"multiturn\"]:\n",
    "    for category, metrics in evaluation_criteria[mode].items():\n",
    "        for sample in data[mode][category]:\n",
    "            sample_id = sample[\"id\"]\n",
    "            for metric in metrics:\n",
    "                token_count = 0\n",
    "                if \"purpose\" in metric:\n",
    "                    token_count = count_tokens(sample.get(\"query\", \"\")) + count_tokens(sample.get(\"answer\", \"\"))\n",
    "                    if \"multiturn\" in metric:\n",
    "                        token_count += sum(count_tokens(turn[\"content\"]) for turn in sample.get(\"history\", []))\n",
    "                elif \"faithfulness\" in metric:\n",
    "                    token_count = sum(count_tokens(ctx) for ctx in sample.get(\"retrieved_contexts_full\", [])) + count_tokens(sample.get(\"answer\", \"\"))\n",
    "                    if \"multiturn\" in metric:\n",
    "                        token_count += sum(count_tokens(turn[\"content\"]) for turn in sample.get(\"history\", []))\n",
    "                elif \"context_relevance\" in metric:\n",
    "                    token_count = sum(count_tokens(ctx) for ctx in sample.get(\"retrieved_contexts_full\", [])) + count_tokens(sample.get(\"query\", \"\"))\n",
    "                    if \"multiturn\" in metric:\n",
    "                        token_count += sum(count_tokens(turn[\"content\"]) for turn in sample.get(\"history\", []))\n",
    "                elif \"answer_correctness\" in metric:\n",
    "                    token_count = count_tokens(sample.get(\"answer\", \"\")) + count_tokens(sample.get(\"reference_answer\", \"\"))\n",
    "                    if \"multiturn\" in metric:\n",
    "                        token_count += sum(count_tokens(turn[\"content\"]) for turn in sample.get(\"history\", []))\n",
    "                elif \"answer_relevance\" in metric:\n",
    "                    token_count = count_tokens(sample.get(\"query\", \"\")) + count_tokens(sample.get(\"answer\", \"\"))\n",
    "                    if \"multiturn\" in metric:\n",
    "                        token_count += sum(count_tokens(turn[\"content\"]) for turn in sample.get(\"history\", []))\n",
    "                elif \"handoff\" in metric:\n",
    "                    token_count = count_tokens(sample.get(\"answer\", \"\"))\n",
    "                elif \"quality_pairwise\" in metric:\n",
    "                    token_count = 2 * count_tokens(sample.get(\"answer\", \"\")) + count_tokens(sample.get(\"query\", \"\"))\n",
    "                    if \"multiturn\" in metric:\n",
    "                            token_count += sum(count_tokens(turn[\"content\"]) for turn in sample.get(\"history\", []))\n",
    "                results.append({\n",
    "                    \"id\": sample_id,\n",
    "                    \"mode\": mode,\n",
    "                    \"category\": category,\n",
    "                    \"metric\": metric,\n",
    "                    \"token_count\": token_count\n",
    "                })\n",
    "\n",
    "# Convert to DataFrame and display again\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "469c3122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total token count for all samples: 818645\n"
     ]
    }
   ],
   "source": [
    "# sum input tokens for all samples\n",
    "total_tokens = df[\"token_count\"].sum()\n",
    "print(f\"Total token count for all samples: {total_tokens}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
